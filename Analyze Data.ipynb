{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8d254c6-45ae-4008-832e-56c229d82b27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Phase 2: Analyze Data\n",
    "\n",
    "Now that we have data on Databricks VM usage, we can analyze that data to understand how many VM's are being used and when they are being used.\n",
    "With this data, we can see how we might optimize our compute configuration. We can also estimate how big our VM instance pools should be to\n",
    "statisfy the compute requirements of our jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2a63f7b-ceab-43ea-8b48-77ebfaaa7c11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "delta_location = \"dbfs:/vm-observation\"\n",
    "\n",
    "observations = spark.read.format(\"delta\").load(delta_location + \"/gold/observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f266fbe-392b-4abf-93bb-6d77cb2c6f16",
     "showTitle": true,
     "title": "Workspaces With Most Usage"
    }
   },
   "outputs": [],
   "source": [
    "display(observations.groupBy(\"subscriptionId\", \"workspaceName\").agg(F.sum(\"count\").alias(\"total_vm_minutes\")).orderBy(F.col(\"total_vm_minutes\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba94c698-c7c6-4f8c-9c75-c02eebc0aae7",
     "showTitle": true,
     "title": "Databricks Jobs With Most Usage"
    }
   },
   "outputs": [],
   "source": [
    "display(observations.groupBy(\"subscriptionId\", \"workspaceName\", \"JobName\").agg(F.sum(\"count\").alias(\"total_vm_minutes\")).orderBy(F.col(\"total_vm_minutes\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a560433-815d-46cd-a198-735df759e3fb",
     "showTitle": true,
     "title": "VM Usage by VM SKU"
    }
   },
   "outputs": [],
   "source": [
    "display(observations.groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\").agg(F.sum(\"count\").alias(\"total_vm_minutes\")).orderBy(F.col(\"total_vm_minutes\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c001471d-ca28-4b81-9bf8-dd33e1663fea",
     "showTitle": true,
     "title": "Usage Summary Report"
    }
   },
   "outputs": [],
   "source": [
    "summary = observations \\\n",
    "            .groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\", \"JobName\") \\\n",
    "            .agg(F.sum(\"count\").alias(\"count\"), F.min(\"date\").alias(\"start\"), F.max(\"date\").alias(\"end\"), F.max(\"count\").alias(\"count_max\"), F.min(\"count\").alias(\"count_min\"), F.countDistinct(\"ClusterName\").alias(\"cluster_count\")) \\\n",
    "            .withColumn(\"minutes\", F.expr(\"((unix_timestamp(end) - unix_timestamp(start)) / 60) + 1\")) \\\n",
    "            .withColumn(\"vms_per_min\", F.expr(\"count / minutes\")) \\\n",
    "            .orderBy(\"subscriptionId\", \"workspaceName\", \"vmSize\", F.col(\"count\").desc())\n",
    "\n",
    "data = summary.collect()\n",
    "\n",
    "subscriptionId = \"\"\n",
    "workspaceName = \"\"\n",
    "vmSize = \"\"\n",
    "\n",
    "htmlCode = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<meta charset=\"utf-8\">\n",
    "<style>\n",
    "body {font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji,FontAwesome;}\n",
    "table {border-collapse: collapse;}\n",
    "th, td {font-size: 9pt; min-width: 18pt; padding: 2pt;}\n",
    "td:nth-child(5), td:nth-child(6), td:nth-child(7), td:nth-child(8), td:nth-child(9), td:nth-child(10) {text-align: right; min-width: 54pt}\n",
    "tr.s td {font-size: 12pt; font-weight: bold; background-color: #cccccc;}\n",
    "tr.w td {font-size: 11pt; font-weight: bold; background-color: #dddddd;}\n",
    "tr.v td {font-size: 10pt; background-color: #eeeeee;}\n",
    "</style>\n",
    "<body><div class=\"markdown\"><table>\n",
    "<thead><tr><th></th><th></th><th></th><th style=\\\"text-align: left\\\">Job Name</th><th>Total VM<br />Minutes</th><th>Concurrent<br/>VMs - Max</th><th>Concurrent<br/>VMs - Min</th><th>Total<br />Minutes</th><th>VMs per<br />Minute</th><th>Number<br />of Runs</th></tr></thead>\n",
    "<tbody>\n",
    "\"\"\"\n",
    "\n",
    "for row in data:\n",
    "    if row[0] != subscriptionId:\n",
    "        subscriptionId = row[0]\n",
    "        htmlCode += f\"<tr class=\\\"s\\\"><td colspan=\\\"10\\\">Subscription: {subscriptionId}</td></tr>\"\n",
    "\n",
    "    if row[1] != workspaceName:\n",
    "        workspaceName = row[1]\n",
    "        htmlCode += f\"<tr class=\\\"w\\\"><td></td><td colspan=\\\"9\\\">Workspace: {workspaceName}</td></tr>\"\n",
    "\n",
    "    if row[2] != vmSize:\n",
    "        vmSize = row[2]\n",
    "        htmlCode += f\"<tr class=\\\"v\\\"><td></td><td></td><td colspan=\\\"8\\\">VM SKU: {vmSize}</td></tr>\"\n",
    "\n",
    "    jobName = row[3] if row[3] else \"[non-job cluster]\"\n",
    "    run_count = format(row[9], \",\") if row[3] else \"-\"\n",
    "    htmlCode += f\"<tr><td></td><td></td><td></td><td>{jobName}</td><td>{row[4]:,}</td><td>{row[7]:,}</td><td>{row[8]:,}</td><td>{int(row[10]):,}</td><td>{row[11]:.2f}</td><td>{run_count}</td></tr>\"\n",
    "\n",
    "htmlCode += \"</tbody></table></div></body></html>\"\n",
    "\n",
    "displayHTML(htmlCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bff5f1c-b93d-4d7f-a253-fa37fd965d89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analyzing Usage for Frequently Occuring Jobs\n",
    "Analysis above looks at all VM usage in Databricks, including VM's that aren't part of on-demand job clusters.  This is useful data\n",
    "to understand Databricks compute consumption across an entire enterprise.  However, to make progress, we need to re-focus on our\n",
    "core purpose here:  We want to increase the resiliency of our regularly occuring Databricks jobs.  We will do this by identifying\n",
    "jobs that are currently powered by on-demand job clusters and move those to Instance Pools.  Therefore, we do not need to be concerned\n",
    "about interactive clusters or jobs that are already running with Instance Pools.  We also don't need to worry about jobs that run\n",
    "sporadically.\n",
    "\n",
    "To that end, the rest of the analysis in this notebook will focus only on \"frequent jobs\".  These are jobs that appear often in the\n",
    "logs during the period of time for which we gathered usage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5cdb1d2-73ba-45ff-a3b3-c9f8d5207f0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dates = observations.agg(F.min(\"date\"), F.max(\"date\")).collect()[0]\n",
    "range_start = dates[0]\n",
    "range_end   = dates[1]\n",
    "range_minutes = (range_end - range_start).total_seconds() / 60\n",
    "\n",
    "frequent_jobs = observations \\\n",
    "                    .groupBy(\"subscriptionId\", \"location\", \"workspaceName\", \"vmSize\", \"JobName\") \\\n",
    "                    .agg(F.min(\"date\").alias(\"start\"), F.max(\"date\").alias(\"end\")) \\\n",
    "                    .withColumn(\"minutes\", F.expr(\"((unix_timestamp(end) - unix_timestamp(start)) / 60) + 1\")) \\\n",
    "                    .withColumn(\"percentage\", F.col(\"minutes\") / F.lit(range_minutes)) \\\n",
    "                    .filter(\"JobName IS NOT NULL AND vmSize IS NOT NULL AND percentage > 0.75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4d5d511-9d0c-477a-ab64-c746903d376b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### VM SKU Variety\n",
    "Each Instance Pool in Databricks can only contain one type of VM.  If we are using many different types of VM's, then we will have to\n",
    "create many instance pools.  That can create extra management overhead.  It can also reduce the efficiency of our pools because spare\n",
    "VM's from one instance pool cannot be used to fill demand in another pool.\n",
    "\n",
    "Therefore, to make our instance pools more efficient, we should consider reducing the number of SKU's that we use as much as possible.\n",
    "In some cases, you may have done very careful testing to select the exact VM SKU that optimizes your workload.  But in other cases\n",
    "(and it seems to be the most common case), a data engineer may have just blindly selected a VM type without putting any thought into it.\n",
    "For these jobs, we might consider changing the VM type and consolidating many jobs into just a few VM types.\n",
    "\n",
    "In the report, a red exclamation mark (‚ùó) is used to indicate an older version of a VM type if you are also using a newer version of\n",
    "that same type.  The report also highlights usage of the \"Standard_DS3_v2\" VM type.  There's nothing wrong with this VM type (it's great, actually!),\n",
    "but it's the default option when creating a compute cluster in Azure Databricks.  It is highlighted simply to illustrate how often your data\n",
    "engineers simply accept the default instead of carefully selecting a VM type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3fe5b41-fe0f-4149-990c-421fe521b047",
     "showTitle": true,
     "title": "VM SKU Variety"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "vm_skus = spark.read.format(\"delta\").load(delta_location + \"/silver/vm_skus\")\n",
    "\n",
    "sku_usage = observations \\\n",
    "                .join(frequent_jobs, on=[\"subscriptionId\", \"location\", \"workspaceName\", \"vmSize\", \"JobName\"], how=\"inner\") \\\n",
    "                .groupBy(\"subscriptionId\", \"location\", \"workspaceName\", \"vmSize\") \\\n",
    "                .agg(F.countDistinct(\"JobName\").alias(\"job_count\"), F.sum(\"count\").alias(\"count\"))\n",
    "\n",
    "order_by_cols = [\"subscriptionId\", \"workspaceName\", \"series\", \"family\", \"number_of_cores\", \"vmSize\"]\n",
    "window_spec = Window.partitionBy(\"subscriptionId\", \"workspaceName\", \"series\").orderBy(order_by_cols)\n",
    "\n",
    "sku_usage = sku_usage \\\n",
    "                .join(vm_skus, (sku_usage.subscriptionId == vm_skus.subscription_id) & (sku_usage.location == vm_skus.location) & (sku_usage.vmSize == vm_skus.name), how=\"left_outer\") \\\n",
    "                .withColumn(\"next_name_without_version\", F.lead(\"name_without_version\").over(window_spec)) \\\n",
    "                .orderBy(order_by_cols) \\\n",
    "                .selectExpr(\"subscriptionId\", \"workspaceName\", \"COALESCE(series, 'Unknown') AS series\", \"family\", \"vmSize\", \"next_name_without_version\", \"name_without_version\", \"description\", \"count\", \"job_count\", \"number_of_cores\", \"memory_in_gb\", \"has_premium_storage\", \"is_amd\", \"has_local_temp_disk\")\n",
    "\n",
    "data = sku_usage.collect()\n",
    "\n",
    "subscriptionId = \"\"\n",
    "workspaceName = \"\"\n",
    "series = \"\"\n",
    "\n",
    "htmlCode = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<meta charset=\"utf-8\">\n",
    "<style>\n",
    "body {font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji,FontAwesome;}\n",
    "table {border-collapse: collapse;}\n",
    "th, td {font-size: 9pt; min-width: 18pt; padding: 2pt;}\n",
    "td:nth-child(5), td:nth-child(6), td:nth-child(7), td:nth-child(8) {text-align: right; min-width: 54pt}\n",
    "td:nth-child(9), td:nth-child(10), td:nth-child(11) {text-align: center; min-width: 54pt}\n",
    "tr.s td {font-size: 12pt; font-weight: bold; background-color: #cccccc;}\n",
    "tr.w td {font-size: 11pt; font-weight: bold; background-color: #dddddd;}\n",
    "tr.v td {font-size: 10pt; background-color: #eeeeee;}\n",
    "tr.highlight td {background-color: orange; color: white}\n",
    "</style>\n",
    "<body><div class=\"markdown\"><table>\n",
    "<thead><tr><th></th><th></th><th></th><th style=\\\"text-align: left\\\">VM SKU</th><th>Total VM<br />Minutes</th><th>Job<br/>Count</th><th>vCPUs</th><th>Memory</th><th>Premium<br/>Storage</th><th>AMD<br />processor</th><th>Local<br />Temp Disk</th></tr></thead>\n",
    "<tbody>\n",
    "\"\"\"\n",
    "\n",
    "for row in data:\n",
    "    row_dict = row.asDict()\n",
    "    if row[0] != subscriptionId:\n",
    "        subscriptionId = row[0]\n",
    "        htmlCode += f\"<tr class=\\\"s\\\"><td colspan=\\\"11\\\">Subscription: {subscriptionId}</td></tr>\"\n",
    "\n",
    "    if row[1] != workspaceName:\n",
    "        workspaceName = row[1]\n",
    "        htmlCode += f\"<tr class=\\\"w\\\"><td></td><td colspan=\\\"10\\\">Workspace: {workspaceName}</td></tr>\"\n",
    "\n",
    "    if row[2] != series:\n",
    "        series = row[2]\n",
    "        htmlCode += f\"<tr class=\\\"v\\\"><td></td><td></td><td colspan=\\\"9\\\">\"\n",
    "        htmlCode += f\"<b>{series} series</b><br />\"\n",
    "        htmlCode += f\"<span style=\\\"font-size: 8pt; font-weight: normal\\\">{row_dict['description']}</span></td></tr>\"\n",
    "\n",
    "    htmlCode += f\"<tr{' class=''highlight''' if row_dict['vmSize'] == 'Standard_DS3_v2' else ''}><td></td><td></td><td></td>\"\n",
    "    htmlCode += f\"<td>{row_dict['vmSize']}{' &#10071;' if row_dict['name_without_version'] == row_dict['next_name_without_version'] else ''}</td>\"\n",
    "    htmlCode += f\"<td>{row_dict['count']:,}</td>\"\n",
    "    htmlCode += f\"<td>{row_dict['job_count']:,}</td>\"\n",
    "    htmlCode += f\"<td>{row_dict['number_of_cores']:,}</td>\"\n",
    "    htmlCode += f\"<td>{int(row_dict['memory_in_gb'])}</td>\"\n",
    "    htmlCode += f\"<td>{'&#9989;' if row_dict['has_premium_storage'] else ''}</td>\"\n",
    "    htmlCode += f\"<td>{'&#9989;' if row_dict['is_amd'] else ''}</td>\"\n",
    "    htmlCode += f\"<td>{'&#9989;' if row_dict['has_local_temp_disk'] else ''}</td>\"\n",
    "    htmlCode += f\"</tr>\"\n",
    "\n",
    "htmlCode += \"</tbody></table></div></body></html>\"\n",
    "\n",
    "displayHTML(htmlCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "143aef9a-912c-479b-9315-c1f355fcc328",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01ca1870-3796-455f-bd68-21f04664851e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c471a0cc-a637-4e2e-8fb9-e0bbd41903db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "order_by_cols = [\"subscriptionId\", \"location\", \"workspaceName\", \"vmSize\", \"JobName\", \"start_date\"]\n",
    "window_spec = Window.partitionBy(\"subscriptionId\", \"location\", \"workspaceName\", \"vmSize\", \"JobName\").orderBy(order_by_cols)\n",
    "\n",
    "job_runs = observations \\\n",
    "            .filter(\"JobName IS NOT NULL AND vmSize IS NOT NULL\") \\\n",
    "            .groupBy(\"subscriptionId\", \"location\", \"workspaceName\", \"vmSize\", \"JobName\", \"JobId\", \"ClusterName\", \"RunName\") \\\n",
    "            .agg(F.sum(\"count\").alias(\"total_count\"), F.avg(\"count\").alias(\"vms_per_minute\"), F.min(\"date\").alias(\"start_date\"), F.max(\"date\").alias(\"end_date\")) \\\n",
    "            .withColumn(\"run_minutes\", F.expr(\"(UNIX_TIMESTAMP(end_date) - UNIX_TIMESTAMP(start_date)) / 60\")) \\\n",
    "            .withColumn(\"previous_start_date\", F.lag(\"start_date\").over(window_spec)) \\\n",
    "            .withColumn(\"hours_between_starts\", F.expr(\"(UNIX_TIMESTAMP(start_date) - UNIX_TIMESTAMP(previous_start_date)) / 3600.0\")) \\\n",
    "            .orderBy(order_by_cols)\n",
    "\n",
    "display(job_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d8f02b4-5521-4890-a9b4-bc2c927f1f21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e6c966e-c47d-47de-b9bd-bda3e5b37cc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "252d28e3-41ee-4ea6-8724-88c41bc0d9d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec08348-6222-43bf-b458-18e36bbe8c0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vm_counts = observations \\\n",
    "                .filter(\"JobName IS NOT NULL\") \\\n",
    "                .groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\", \"JobName\", \"date\") \\\n",
    "                .agg(F.sum(\"count\").alias(\"count\"))\n",
    "\n",
    "all_dates = spark.range(0, range_minutes).withColumn(\"date\", F.lit(range_start) + F.expr(\"MAKE_INTERVAL(0, 0, 0, 0, 0, id)\")).drop(\"id\").orderBy(\"date\")\n",
    "\n",
    "df = frequent_jobs.select(\"subscriptionId\", \"workspaceName\", \"vmSize\", \"JobName\") \\\n",
    "        .crossJoin(all_dates)\n",
    "\n",
    "df = df \\\n",
    "        .join(vm_counts.alias(\"v\"), [\"subscriptionId\", \"workspaceName\", \"vmSize\", \"JobName\", \"date\"], \"leftouter\") \\\n",
    "        .withColumn(\"count\", F.coalesce(F.col(\"count\"), F.lit(0))) \\\n",
    "        .groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\", \"jobName\", \"date\") \\\n",
    "        .agg(F.sum(\"count\").alias(\"count\")) \\\n",
    "        .withColumn(\"job_active\", F.expr(\"CASE WHEN count > 0 THEN jobName ELSE NULL END\")) \\\n",
    "        .cache()\n",
    "\n",
    "display( df.groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\").agg(F.min(\"count\"), F.max(\"count\").alias(\"max_count\")) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3f4ced1-1b68-49d2-9dda-6c5d3ba50d35",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Inspection by VM SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77860f52-d1a2-4f11-abe5-a30b69b73b2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "subscription_id = \"ee691273-18af-4600-bc24-eb6768bf9cfa\"\n",
    "workspace_name = \"dde-prod-dbks-w1\"\n",
    "vm_size = \"Standard_DS4_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc3fdcbe-2b36-4332-b9b5-05d534906954",
     "showTitle": true,
     "title": "VM Usage Aggregated by Minute"
    }
   },
   "outputs": [],
   "source": [
    "subset = df.filter(f\"subscriptionId == '{subscription_id}' AND workspaceName == '{workspace_name}' AND vmSize == '{vm_size}'\")\n",
    "subset = subset.withColumn(\"minute\", F.minute(\"date\"))\n",
    "subset = subset.withColumn(\"job_active\", F.expr(\"CASE WHEN count > 0 THEN jobName ELSE NULL END\"))\n",
    "subset = subset.groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\", \"minute\").agg(F.sum(\"count\").alias(\"count\"), F.countDistinct(\"job_active\").alias(\"job_count\"))\n",
    "display(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8f7c4f1-5f54-44c2-9380-b95ba141cf72",
     "showTitle": true,
     "title": "Daily Usage Visualization"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "date_range = observations.agg(F.min(\"date\"), F.max(\"date\")).collect()[0]\n",
    "first_full_day = date_range[0].date() + timedelta(days = 1)\n",
    "last_full_day  = date_range[1].date() - timedelta(days = 1)\n",
    "days_count = (last_full_day - first_full_day).days + 1\n",
    "days = [first_full_day + timedelta(days=i) for i in range(0, days_count)]\n",
    "\n",
    "daily = df \\\n",
    "            .withColumn(\"day\", F.to_date(\"date\")) \\\n",
    "            .withColumn(\"time\", F.expr(\"date - MAKE_INTERVAL(0, 0, 0, DATEDIFF(date, '2000-01-01'))\")) \\\n",
    "            .filter(f\"subscriptionId == '{subscription_id}' AND workspaceName == '{workspace_name}' AND vmSize == '{vm_size}'\") \\\n",
    "            .filter(f\"day BETWEEN '{first_full_day}' AND '{last_full_day}'\") \\\n",
    "            .groupBy(\"subscriptionId\", \"workspaceName\", \"vmSize\", \"date\", \"day\", \"time\") \\\n",
    "            .agg(F.sum(\"count\").alias(\"count\")) \\\n",
    "            .cache()\n",
    "\n",
    "max_count = daily.agg(F.max(\"count\")).collect()[0][0]\n",
    "fig, ax = plt.subplots(days_count, 1, figsize=(24, (4 * days_count) + 2))\n",
    "hour_locator = mdates.HourLocator(interval=1)\n",
    "hour_formatter = mdates.DateFormatter(\"%H\")\n",
    "\n",
    "for i, day in enumerate(days):\n",
    "    data = daily.filter(f\"day = '{day}'\").orderBy(\"date\").toPandas()\n",
    "    X = data[\"time\"]\n",
    "    Y = data[\"count\"]\n",
    "\n",
    "    ax[i].plot(X, Y, color='black')\n",
    "    ax[i].fill_between(X, Y, 0, color='tomato')\n",
    "\n",
    "    ax[i].xaxis.set_major_locator(hour_locator)\n",
    "    ax[i].xaxis.set_major_formatter(hour_formatter)\n",
    "    ax[i].set_ylim([0, max_count + 1])\n",
    "    ax[i].set_xlim(pd.Timestamp('2000-01-01'), pd.Timestamp('2000-01-01 23:59:59'))\n",
    "    ax[i].set_ylabel(day, fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle(f\"Daily VM Usage     Workspace: {workspace_name}     VM SKU: {vm_size}\", fontsize=30)\n",
    "fig.subplots_adjust(top=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cfc3cd5-f216-421b-985f-fe2d4f8c1fde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Analyze Data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
